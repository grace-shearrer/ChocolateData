{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making a function for the decoding\n",
    "Testing on a small dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code used for batches below "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install xdot --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda2/envs/py36/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "/anaconda2/envs/py36/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/anaconda2/envs/py36/lib/python3.6/importlib/_bootstrap.py:219: ImportWarning: can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n",
      "  return f(*args, **kwds)\n",
      "/anaconda2/envs/py36/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/anaconda2/envs/py36/lib/python3.6/importlib/_bootstrap.py:219: ImportWarning: can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import nilearn\n",
    "import nibabel as nib\n",
    "import pandas as pd \n",
    "from sklearn.model_selection import cross_val_score\n",
    "from nilearn.input_data import NiftiMasker \n",
    "import numpy as np\n",
    "np.seterr(divide='ignore', invalid='ignore')\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_selection import SelectPercentile, f_classif, SelectKBest\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from beaker.cache import CacheManager\n",
    "from beaker.util import parse_cache_config_options\n",
    "import objgraph\n",
    "# import xdot\n",
    "import pdb\n",
    "\n",
    "import multiprocessing\n",
    "from multiprocessing import Pool\n",
    "\n",
    "import time\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cache Money"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cache_opts = {\n",
    "    'cache.type': 'file',\n",
    "    'cache.data_dir': '/Users/gracer/Google Drive/decode/tmp/data',\n",
    "    'cache.lock_dir': '/Users/gracer/Google Drive/decode/tmp/lock',\n",
    "    'cache.regions' : 'short_term, long_term'\n",
    "}\n",
    "\n",
    "cache = CacheManager(**parse_cache_config_options(cache_opts))\n",
    "\n",
    "tmpl_cache = cache.get_cache('/Users/gracer/Google Drive/decode/tmp/mytemplate.html', type='dbm', expire=3600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "will want to cache the following:\n",
    "* masker\n",
    "* the fit (X)\n",
    "* anova_svc\n",
    "* y_pred\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitter function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "@cache.cache('short_term')\n",
    "def fitter(IMAG_MASK, DATASET, LABELS ,CONDITION_MASK, ANOVA_SVC, CONDITIONS):\n",
    "    masker = NiftiMasker(mask_img=IMAG_MASK, standardize=True, memory=\"nilearn_cache\", memory_level=1)\n",
    "    X = masker.fit_transform(DATASET.func[0])\n",
    "    \n",
    "    # Apply our condition_mask\n",
    "    X = X[CONDITION_MASK]\n",
    "\n",
    "    \n",
    "#     ANOVA_SVC.fit(X,CONDITIONS)\n",
    "#     y_pred = ANOVA_SVC.predict(X)\n",
    "    \n",
    "    return([ANOVA_SVC.fit(X,CONDITIONS),X])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NESTED CROSS VALIDATION\n",
    "\n",
    "def run_CV(MODEL, PARAMS):\n",
    "    grid = GridSearchCV(MODEL, param_grid={'anova__k': PARAMS}, verbose=1, cv=5, n_jobs=4)\n",
    "    return cross_val_score(grid, X, y, cv=5)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['face' 'house']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('anova', SelectKBest(k=500, score_func=<function f_classif at 0x1c1059c268>)), ('svc', SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False))])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "haxby_dataset = nilearn.datasets.fetch_haxby()\n",
    "ANOVA_SVC=test(haxby_dataset, haxby_dataset.mask, pd.read_csv(haxby_dataset.session_target[0], sep=\" \"))\n",
    "    \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "k_range = [[ 15, 50, 150, 300], [500, 1000, 3000, 5000]]\n",
    "ANOVA_SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/anaconda2/envs/py36/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n    result = (True, func(*args, **kwds))\n  File \"/anaconda2/envs/py36/lib/python3.6/multiprocessing/pool.py\", line 44, in mapstar\n    return list(map(*args))\n  File \"<ipython-input-30-791a05997a77>\", line 3, in run_CV\n    return cross_val_score(grid, X, y, cv=5)\nNameError: name 'X' is not defined\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-791a05997a77>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocesses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mnested_cv_scores\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_CV\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk_range\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/envs/py36/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    264\u001b[0m         \u001b[0;32min\u001b[0m \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mthat\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mreturned\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m         '''\n\u001b[0;32m--> 266\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_map_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmapstar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstarmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/envs/py36/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    642\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 644\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    645\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    646\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "def run_CV(params):\n",
    "    grid = GridSearchCV(ANOVA_SVC, param_grid={'anova__k': params}, verbose=1, cv=5, n_jobs=4)\n",
    "    return cross_val_score(grid, X, y, cv=5)\n",
    "        \n",
    "  \n",
    "        \n",
    "\n",
    "p = Pool(processes = 4) \n",
    "start = time.time()\n",
    "nested_cv_scores =  p.map(run_CV, k_range)\n",
    "p.close()\n",
    "p.join()\n",
    "print(\"Nested CV score: %.4f\" % np.mean(nested_cv_scores))\n",
    "print(\"Time: \", (time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['face' 'house']\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-448a0b4f6611>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrun_CV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhaxby_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhaxby_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhaxby_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession_target\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk_range\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-20-cbcaeba525f1>\u001b[0m in \u001b[0;36mrun_CV\u001b[0;34m(MODEL, PARAMS)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mrun_CV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMODEL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPARAMS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mgrid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMODEL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'anova__k'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mPARAMS\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "run_CV(test(haxby_dataset, haxby_dataset.mask, pd.read_csv(haxby_dataset.session_target[0], sep=\" \")), k_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(DATASET, MASK, BEHAVIORAL):\n",
    "    from sklearn.svm import SVC\n",
    "    from sklearn.feature_selection import SelectPercentile, f_classif, SelectKBest\n",
    "    from sklearn.pipeline import Pipeline\n",
    "\n",
    "    svc = SVC(kernel='linear')\n",
    "    FEATURE_SELECTION = SelectKBest(f_classif, k=500)\n",
    "    ANOVA_SVC = Pipeline([('anova', FEATURE_SELECTION), ('svc', svc)])\n",
    "    \n",
    "    #image mask\n",
    "    IMAG_MASK=MASK\n",
    "\n",
    "    BEHAVIORAL = BEHAVIORAL\n",
    "    CONDITIONS = BEHAVIORAL['labels']\n",
    "\n",
    "    #our dataset concatenated image \n",
    "    DATASET=DATASET\n",
    "\n",
    "    LABELS = BEHAVIORAL[\"labels\"]\n",
    "    #restrict data to our target analysis \n",
    "    CONDITION_MASK = BEHAVIORAL['labels'].isin(['face', 'house'])\n",
    "    CONDITIONS = CONDITIONS[CONDITION_MASK]\n",
    "\n",
    "    #confirm we have the # of condtions needed\n",
    "    print(CONDITIONS.unique())\n",
    "    [ANOVA_SVC_FIT,X]=fitter(IMAG_MASK, DATASET, LABELS ,CONDITION_MASK, ANOVA_SVC, CONDITIONS)\n",
    "    return(ANOVA_SVC_FIT)\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def parallel_runs(data_list):\n",
    "    pool = multiprocessing.Pool(processes=4)\n",
    "    ANOVA_SVC_FIT = test(haxby_dataset, haxby_dataset.mask, pd.read_csv(haxby_dataset.session_target[0], sep=\" \"))\n",
    "    pdb.set_trace()\n",
    "    \n",
    "    prod_x=partial(run_CV, MODEL=ANOVA_SVC_FIT) \n",
    "    result_list = pool.map(prod_x, data_list) \n",
    "    print(result_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['face' 'house']\n",
      "> <ipython-input-12-8ccaf5747bd2>(6)parallel_runs()\n",
      "-> prod_x=partial(run_CV, MODEL=ANOVA_SVC_FIT)\n",
      "(Pdb) ANOVA_SVC_FIT\n",
      "Pipeline(memory=None,\n",
      "     steps=[('anova', SelectKBest(k=500, score_func=<function f_classif at 0x1c1059c268>)), ('svc', SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False))])\n",
      "(Pdb) c\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "run_CV() got multiple values for argument 'MODEL'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/anaconda2/envs/py36/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n    result = (True, func(*args, **kwds))\n  File \"/anaconda2/envs/py36/lib/python3.6/multiprocessing/pool.py\", line 44, in mapstar\n    return list(map(*args))\nTypeError: run_CV() got multiple values for argument 'MODEL'\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-98b05e1c5b2b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mparallel_runs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk_range\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Nested CV score: %.4f\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnested_cv_scores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Time: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-8ccaf5747bd2>\u001b[0m in \u001b[0;36mparallel_runs\u001b[0;34m(data_list)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mANOVA_SVC_FIT\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhaxby_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhaxby_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhaxby_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession_target\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mprod_x\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_CV\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMODEL\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mANOVA_SVC_FIT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mresult_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprod_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/envs/py36/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    264\u001b[0m         \u001b[0;32min\u001b[0m \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mthat\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mreturned\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m         '''\n\u001b[0;32m--> 266\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_map_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmapstar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstarmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/envs/py36/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    642\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 644\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    645\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    646\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: run_CV() got multiple values for argument 'MODEL'"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    start = time.time()\n",
    "    parallel_runs(k_range)\n",
    "    print(\"Nested CV score: %.4f\" % np.mean(nested_cv_scores))\n",
    "    print(\"Time: \", (time.time() - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing 1, 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load target information as string and give a numerical identifier to each\n",
    "behavioral = pd.read_csv(haxby_dataset.session_target[0], sep=\" \")\n",
    "conditions = behavioral['labels']\n",
    "\n",
    "# Restrict the analysis to faces and places\n",
    "condition_mask = behavioral['labels'].isin(['face', 'house'])\n",
    "conditions = conditions[condition_mask]\n",
    "\n",
    "# Confirm that we now have 2 conditions\n",
    "print(conditions.unique())\n",
    "\n",
    "# Record these as an array of sessions, with fields\n",
    "# for condition (face or house) and run\n",
    "session = behavioral[condition_mask].to_records(index=False)\n",
    "print(session.dtype.names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "haxby_dataset = nilearn.datasets.fetch_haxby()\n",
    "main(haxby_dataset, haxby_dataset.mask, pd.read_csv(haxby_dataset.session_target[0], sep=\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# masker = NiftiMasker(mask_img=imag_mask, standardize=True, memory=\"nilearn_cache\", memory_level=1)\n",
    "# X = masker.fit_transform(dataset)\n",
    "# # Apply our condition_mask\n",
    "# X = X[condition_mask]\n",
    "\n",
    "\n",
    "\n",
    "# # PREDICTION FUNCTION\n",
    "# svc = SVC(kernel='linear')\n",
    "\n",
    "# # FEATURE SELECTION\n",
    "# feature_selection = SelectKBest(f_classif, k=500)\n",
    "\n",
    "\n",
    "# anova_svc = Pipeline([('anova', feature_selection), ('svc', svc)])\n",
    "# anova_svc.fit(X,y)\n",
    "# y_pred = anova_svc.predict(X)\n",
    "\n",
    "# # NESTED CROSS VALIDATION \n",
    "# nested_cv_scores = cross_val_score(anova_svc, X, y,  cv=5) \n",
    "# #cv_scores = cross_val_score(anova_svc, X, conditions,)\n",
    "# # Print the results\n",
    "# print(\"Nested CV score: %.4f\" % np.mean(nested_cv_scores))\n",
    "\n",
    "\n",
    "# # In[ ]:\n",
    "\n",
    "\n",
    "# # Here is the image \n",
    "# coef = svc.coef_\n",
    "# # reverse feature selection\n",
    "# coef = feature_selection.inverse_transform(coef)\n",
    "# # reverse masking\n",
    "# weight_img = masker.inverse_transform(coef)\n",
    "\n",
    "\n",
    "# # Use the mean image as a background to avoid relying on anatomical data\n",
    "# from nilearn import image\n",
    "# mean_img = image.mean_img(dataset)\n",
    "# mean_img.to_filename('/projects/niblab/bids_projects/Experiments/ChocoData/derivatives/code/decoding/milkshake_vs_h2O/images/all/all_waves_b%s_mean_nimask.nii'%batchID)\n",
    "\n",
    "# # Create the figure\n",
    "# from nilearn.plotting import plot_stat_map, show\n",
    "# display = plot_stat_map(weight_img, mean_img, title='Milkshake vs. h2O')\n",
    "# display.savefig('/projects/niblab/bids_projects/Experiments/ChocoData/derivatives/code/decoding/milkshake_vs_h2O/images/all/all_waves_b%s_SVM_nimask.png'%batchID)\n",
    "# # Saving the results as a Nifti file may also be important\n",
    "# weight_img.to_filename('/projects/niblab/bids_projects/Experiments/ChocoData/derivatives/code/decoding/milkshake_vs_h2O/images/all/all_waves_b%s_SVM_nimask.nii'%batchID)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn import datasets\n",
    "\n",
    "# By default 2nd subject will be fetched\n",
    "haxby_dataset = datasets.fetch_haxby()\n",
    "\n",
    "# print basic information on the dataset\n",
    "print('Mask nifti image (3D) is located at: %s' % haxby_dataset.mask)\n",
    "print('Functional nifti image (4D) is located at: %s' %\n",
    "      haxby_dataset.func[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load target information as string and give a numerical identifier to each\n",
    "behavioral = pd.read_csv(haxby_dataset.session_target[0], sep=\" \")\n",
    "conditions = behavioral['labels']\n",
    "\n",
    "# Restrict the analysis to faces and places\n",
    "condition_mask = behavioral['labels'].isin(['face', 'house'])\n",
    "conditions = conditions[condition_mask]\n",
    "\n",
    "# Confirm that we now have 2 conditions\n",
    "print(conditions.unique())\n",
    "\n",
    "# Record these as an array of sessions, with fields\n",
    "# for condition (face or house) and run\n",
    "session = behavioral[condition_mask].to_records(index=False)\n",
    "print(session.dtype.names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.input_data import NiftiMasker\n",
    "\n",
    "mask_filename = haxby_dataset.mask\n",
    "\n",
    "# For decoding, standardizing is often very important\n",
    "# note that we are also smoothing the data\n",
    "masker = NiftiMasker(mask_img=mask_filename, smoothing_fwhm=4,\n",
    "                     standardize=True, memory=\"nilearn_cache\", memory_level=1)\n",
    "func_filename = haxby_dataset.func[0]\n",
    "X = masker.fit_transform(func_filename)\n",
    "# Apply our condition_mask\n",
    "X = X[condition_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn import image\n",
    "MEAN_IMG = image.mean_img(haxby_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "haxby_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
