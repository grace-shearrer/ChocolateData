{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn import datasets\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from nilearn.input_data import NiftiMasker\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import multiprocessing\n",
    "from multiprocessing import Pool\n",
    "from functools import partial\n",
    "from beaker.cache import CacheManager\n",
    "from beaker.util import parse_cache_config_options\n",
    "from nilearn import datasets #only needed if testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cache\n",
    "Here we can outline the cache options we would like to save and then initallize it before the main() is called."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "cache_opts = {\n",
    "    'cache.type': 'file',\n",
    "    'cache.data_dir': '/Users/gracer/Google Drive/decode/tmp/data',\n",
    "    'cache.lock_dir': '/Users/gracer/Google Drive/decode/tmp/lock',\n",
    "    'cache.regions' : 'short_term'\n",
    "}\n",
    "\n",
    "cache = CacheManager(**parse_cache_config_options(cache_opts))\n",
    "\n",
    "tmpl_cache = cache.get_cache('/Users/gracer/Google Drive/decode/tmp/mytemplate.html', type='dbm', expire=3600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main function\n",
    "This function takes in the data files and is the only one that needs to be explictly called"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "@cache.cache('short_term')\n",
    "def main(DATA, LABELS, MASK, FUNC):\n",
    "    y = LABELS['labels']\n",
    "    session = LABELS['chunks']\n",
    "    condition_mask = y.isin(['shoe', 'bottle'])\n",
    "    y = y[condition_mask]\n",
    "    mask_filename = MASK\n",
    "    \n",
    "    svc = SVC(kernel='linear')\n",
    "\n",
    "    k_range = [[10, 15, 30, 50, 150], [300, 500, 1000, 1500, 3000, 5000]]\n",
    "\n",
    "    # Define the dimension reduction to be used.\n",
    "    # Here we use a classical univariate feature selection based on F-test,\n",
    "    # namely Anova. We set the number of features to be selected to 500\n",
    "    feature_selection = SelectKBest(f_classif, k=500)\n",
    "\n",
    "    # We have our classifier (SVC), our feature selection (SelectKBest), and now,\n",
    "    # we can plug them together in a *pipeline* that performs the two operations\n",
    "    # successively:\n",
    "    anova_svc = Pipeline([('anova', feature_selection), ('svc', svc)])\n",
    "    \n",
    "    \n",
    "    \n",
    "    X=masker(MASK, FUNC, condition_mask, session)\n",
    "    \n",
    "    parallel_runs(anova_svc, X, y, k_range)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Masker\n",
    "This function takes in the mask image, conditions, session if necessary. It will return the X value that the CV_Scores will need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def masker(MASK, FUNC, condition_mask, session):\n",
    "    # For decoding, standardizing is often very important\n",
    "    nifti_masker = NiftiMasker(mask_img=MASK, sessions=session,\n",
    "                               smoothing_fwhm=4, standardize=True,\n",
    "                               memory=\"nilearn_cache\", memory_level=1)\n",
    "    func_filename = FUNC\n",
    "    X = nifti_masker.fit_transform(func_filename)\n",
    "    # Restrict to non rest data\n",
    "    X = X[condition_mask]\n",
    "    session = session[condition_mask]\n",
    "    return(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CV_Scores\n",
    "This will take in the k range we want to calculate, the model that was build in main, the X from masker, and y from main. This is never explicitly called, it is called within the partial function and in the parallel function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CV_Scores(k_range, model,X, y):\n",
    "    grid = GridSearchCV(model, param_grid={'anova__k': k_range}, verbose=1,\n",
    "                    cv=3)\n",
    "    nested_cv_scores = cross_val_score(grid, X, y, cv=3)\n",
    "\n",
    "    print(\"Nested CV score: %.4f\" % np.mean(nested_cv_scores))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parallel\n",
    "This function is used to speed up the CV_Scoring process. It must be called in the main function. It expects the model, X, y and the range of K values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parallel_runs(model, X, y, k_range):\n",
    "    pool = multiprocessing.Pool(multiprocessing.cpu_count())\n",
    "    prod_x=partial(CV_Scores, model=model, X=X, y=y) \n",
    "    result_list = pool.map(prod_x, k_range) \n",
    "    print(result_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Globals\n",
    "You will need to read in the dataset (images), the mask, and the behavioral data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "data= datasets.fetch_haxby()\n",
    "func = data.func[0]\n",
    "data0 = pd.read_csv(data.session_target[0], sep=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed:    1.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  18 out of  18 | elapsed:    2.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed:    1.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed:    2.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nested CV score: 0.5093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  18 out of  18 | elapsed:    3.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  18 out of  18 | elapsed:    2.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nested CV score: 0.5972\n",
      "[None, None]\n"
     ]
    }
   ],
   "source": [
    "main(data , data0, data.mask, func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
